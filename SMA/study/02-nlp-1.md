# Module 2 — NLP in Social Media Analytics - 1

## Topics

- [[#2.1 Sentiment Analysis|Sentiment Analysis]]
- [[#2.2 Document Sentiment Classification|Document Sentiment Classification]]
- [[#2.3 Sentence Subjectivity & Sentiment Classification|Sentence Subjectivity & Sentiment Classification]]
- [[#2.4 Aspect-Based Sentiment Analysis|Aspect-Based Sentiment Analysis]]
- [[#2.5 Opinion Summarization|Opinion Summarization]]
- [[#2.6 Opinion Spam Detection|Opinion Spam Detection]]

---

## 2.1 Sentiment Analysis

- **Sentiment analysis** (opinion mining): computational study of opinions, sentiments, emotions expressed in text
- Core task: determine the **polarity** (positive, negative, neutral) of a piece of text
- Central to social media analytics — understanding what people think about products, services, events

### Levels of Sentiment Analysis

| Level | Scope | Example |
|-------|-------|---------|
| **Document-level** | Entire document | "Is this review positive or negative?" |
| **Sentence-level** | Individual sentence | "Is this sentence subjective? What is its polarity?" |
| **Aspect-level** | Specific entity/aspect | "The battery is great but the screen is poor" |

### Sentiment Analysis Pipeline

1. **Data collection** — gather text from social media, reviews, forums
2. **Preprocessing** — tokenization, stopword removal, normalization
3. **Feature extraction** — BoW, TF-IDF, word embeddings
4. **Classification** — ML/DL models for polarity prediction
5. **Evaluation** — accuracy, F1-score, precision, recall

---

## 2.2 Document Sentiment Classification

- Treat the entire document as a unit and classify its overall sentiment
- Assumption: the document expresses opinion on a **single entity**

### Approaches

#### Supervised Learning

- **Features**: bag-of-words, n-grams, POS tags, sentiment lexicon features
- **Classifiers**: Naive Bayes, SVM, Logistic Regression, Random Forest
- Key finding (Pang & Lee, 2002): **unigram presence** (binary BoW) often outperforms frequency-based features

#### Unsupervised / Lexicon-Based

- Use **sentiment lexicons** (lists of words with polarity scores)
  - Examples: SentiWordNet, VADER, AFINN, Bing Liu's Opinion Lexicon
- Score = sum of positive word scores − sum of negative word scores
- Advantages: no training data needed, domain-independent
- Limitations: misses context, negation, sarcasm

#### Deep Learning

- **CNN** for text classification: captures local n-gram patterns
- **LSTM/BiLSTM**: captures sequential dependencies
- **BERT and transformers**: state-of-the-art, captures contextual meaning

---

## 2.3 Sentence Subjectivity & Sentiment Classification

### Subjectivity Classification

- Determine if a sentence is **subjective** (opinion) or **objective** (fact)
- Examples:
  - Subjective: "This phone is amazing!"
  - Objective: "This phone has a 6.1-inch display."
- Features: presence of adjectives, adverbs, opinion words

### Sentence-Level Sentiment Classification

- For subjective sentences, determine **polarity**: positive, negative, neutral
- Challenges at the sentence level:
  - **Negation**: "This is not good" — reverses polarity
  - **Comparative sentences**: "X is better than Y"
  - **Conditional**: "If they fix the bugs, it would be great"
  - **Sarcasm**: "Oh great, another update that breaks everything"

### Handling Negation

- Simple approach: negate all words between negation word and next punctuation
- More sophisticated: parse tree-based negation scope detection
- Negation shifts polarity: positive → negative and vice versa

---

## 2.4 Aspect-Based Sentiment Analysis

- **Goal**: identify **aspects** (features/attributes) of an entity and the sentiment expressed toward each aspect
- Example: "The food was excellent but the service was terrible"
  - Aspect: food → positive; Aspect: service → negative

### Steps

1. **Aspect extraction**: identify aspects mentioned in text
   - Frequent noun/noun-phrase extraction
   - Dependency parsing
   - Topic modeling (LDA)
   - Sequence labeling (CRF, BiLSTM-CRF)
2. **Aspect sentiment classification**: determine polarity for each aspect
   - Attention-based neural models
   - Aspect-aware BERT models

### Aspect Categories

- **Explicit aspects**: directly mentioned ("battery life is good")
- **Implicit aspects**: implied but not explicitly stated ("too expensive" → price)

### Opinion Targets and Opinion Words

- **Opinion target**: the entity/aspect being evaluated
- **Opinion word**: the word expressing the sentiment
- Extracting (target, opinion) pairs is a key task

---

## 2.5 Opinion Summarization

- **Goal**: present a summary of opinions from multiple reviews/posts
- Users don't want to read thousands of reviews — need concise summaries

### Approaches

#### Aspect-Based Opinion Summary

- For each aspect:
  - Count positive vs. negative opinions
  - Show representative sentences
  - Visualize as bar charts or star ratings

#### Structured Summary Format

```
Entity: iPhone 15
  Aspect: Battery    → Positive: 78%, Negative: 22%
  Aspect: Camera     → Positive: 91%, Negative: 9%
  Aspect: Price      → Positive: 35%, Negative: 65%
```

#### Abstractive Opinion Summarization

- Use NLP/NLG models to generate natural language summaries
- Transformer-based models (GPT, T5) for abstractive summaries
- Challenge: faithfulness — summary must accurately reflect opinions

---

## 2.6 Opinion Spam Detection

- **Opinion spam**: fake or deceptive reviews designed to mislead
- Types:
  - **Untruthful opinions**: fake positive/negative reviews
  - **Reviews on brand only**: not about specific product experience
  - **Non-reviews**: advertisements, irrelevant content

### Detection Approaches

| Method | Description |
|--------|-------------|
| **Content-based** | Analyze linguistic patterns — duplicates, excessive superlatives |
| **Behavior-based** | Reviewer patterns — burst of reviews, one-time reviewers, review timing |
| **Network-based** | Reviewer-product bipartite graph analysis, collusion detection |
| **Machine learning** | SVM, Random Forest using linguistic + behavioral features |

### Key Indicators of Fake Reviews

- Excessive use of first-person pronouns
- Lack of specific product details
- Deviation from typical rating distributions
- Reviewer has reviewed only one brand
- Temporal bursts of reviews

---

## Key Takeaways

- Sentiment analysis operates at document, sentence, and aspect levels
- Lexicon-based methods are simple but limited; ML/DL methods are more powerful
- Aspect-based analysis provides fine-grained insights into opinions
- Opinion summarization condenses large volumes of reviews into actionable summaries
- Opinion spam is a critical problem — detection uses content, behavior, and graph features

---

## References

- T2: Bing Liu, *Sentiment Analysis and Opinion Mining* — Topics 1 thru 5, Topic 10
